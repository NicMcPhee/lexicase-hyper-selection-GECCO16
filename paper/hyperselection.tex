% This is "sig-alternate.tex" V2.1 April 2013
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% --------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate}

\usepackage{longtable}
\usepackage{tabu}
\usepackage{multirow}

%\usepackage[hyphens]{url}
\usepackage{rotating}
\usepackage{underscore}

\usepackage{booktabs}
\usepackage[table]{xcolor}
\definecolor{Gray}{gray}{0.9}

\usepackage{todonotes}

\newcommand{\definition}[1]{\textit{#1}}

\begin{document}

% Copyright
\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}



% DOI
\doi{10.475/123_4}

% ISBN
\isbn{123-4567-24-567/08/06}



\acmPrice{\$15.00}

%
% --- Author Metadata here ---
%Conference
\conferenceinfo{GECCO'16,} {July 20-24, 2016, Denver, Colorado, USA.}
\CopyrightYear{2016}
\crdata{TBA}
\clubpenalty=10000
\widowpenalty = 10000
% --- End of Author Metadata ---

\title{The Impact of Hyperselection on Lexicase Selection}

%\subtitle{[Extended Abstract]}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Author omitted\\
       \affaddr{.}\\
       \affaddr{.}\\
       \affaddr{.}\\
       \email{.}
% 2nd. author
\alignauthor
Author omitted\\
       \affaddr{.}\\
       \affaddr{.}\\
       \affaddr{.}\\
       \email{.}
% 3rd. author
\alignauthor
Author omitted\\
       \affaddr{.}\\
       \affaddr{.}\\
       \affaddr{.}\\
       \email{.}
}

% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}

	It has been noted in previous work that lexicase selection, while extremely successful on a broad range of software synthesis problems, is occasionally quite aggressive in its selections. In extreme cases a single individual
	can receive over 90\% of the selections in a particular generation. These kinds of \emph{hyperselections} are mathematically impossible when using many other selection methods such as tournament selection.
	
	Here we explore the frequency of hyperselections in genetic programming runs using both tournament and lexicase selection, and document that hyperselections indeed occur using lexicase selection at levels impossible to achieve with tournament selection. The new \emph{sampled lexicase-tournament selection} mechanism is introduced, which chooses individuals from a pool similar to that selected by lexicase, but with frequencies similar to those when using tournament selection. We find that sampled lexicase-tournament selection performs comparably to lexicase selection on a collection of benchmark problems, and again far better than tournament. This finding indicates that hyperselection is not critical to the success of lexicase selection, and instead that it is more important \textit{which} individuals lexicase selects rather than how often they are selected.

\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>  
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}


%
% End generated code
%

%
%  Use this command to print the description
%
\printccsdesc

% We no longer use \terms command
%\terms{Theory}

\keywords{Do we need keywords?}

\section{Introduction}
\label{section:introduction}

Intro. Lexicase \cite{Helmuth:2014:ieeeTEC}.

\todo[inline]{I've yanked the following content from other parts of the initial copy/paste draft because it seemed like they made more sense in the intro. - Nic}

Evolutionary algorithms use selection pressure to direct search, with the goal of refining promising programs into better ones. This exploitation of already-discovered individuals helps drive search toward solutions. Almost all parent selection mechanisms select some individuals more than others, but vary in how they bias selection.\footnote{An exception is uniform selection, which does not bias selection.}

In previous work~\cite{Helmuth:2015:GPTP,Helmuth:2015:dissertation} we noted that lexicase selection~\cite{Helmuth:2014:ieeeTEC} often gave many parent selections to single individuals, including some individuals that fell quite low in rankings based on total error. This extreme exploitation of specific individuals strongly contrasts to how often we would expect tournament selection to select any individual, let alone one with poor total error. In this paper, we will systematically investigate the hyper-selection of single individuals in GP using lexicase selection.


\section{Hyperselection}
\label{section:hyperselection}

Let us call an individual \definition{hyper-selected at the $X\%$ level} if that individual receives at least $X\%$ of the parent selections in a single generation. For example, an individual that receives at least 170 selections out of 1700 total in a generation is considered hyper-selected at the 10\% level (as well as any level below 10\%). Examining hyper-selection events can help us characterize how often single individuals receive a large percent of the selections in their generations; here, we will %(somewhat arbitrarily) 
look at hyper-selection events at the 1\%, 5\%, and 10\% levels.

With tournament selection, the number of times an individual can be selected is limited by the number of tournaments in which it participates. If the best member of the population participates in 1\% of the tournaments for a given generation, it will be selected 1\% of the time that generation, but no more.
 Since the expected number of tournaments in which each individual participates is constant for a particular population size $P$ and tournament size $t$, the probability of an individual being selected by tournament selection is entirely determined by its rank in the population. In particular, the probability of selecting an individual with rank $i \in [1,P]$, with $i = 1$ being the best rank, is
\begin{equation}\label{tourneyProbEquation}
p(i) = \frac{(P-i+1)^t - (P-i)^t}{P^t}
\end{equation}
assuming no two individuals have the same fitness~\cite{350042, Blickle:1995:MAT:645514.658088}. With ties in the rankings, this equation does not hold exactly, but is approximately correct unless there are many tied individuals. We plot this probability mass function in Figure~\ref{fig:prob-selection-tourney-7}.

\begin{figure}[t] %[t] sets the image at the top of the page; t = top, b = bottom, h = here%
\centering
\includegraphics[width=\linewidth]{probSelectionTourney7.pdf}
\caption{Probability mass function of selecting individual with rank $i$ out of a population of 1000 individuals using tournament selection with tournament size 7, assuming no two individuals have the same rank. This plots Equation~\ref{tourneyProbEquation}.}
\label{fig:prob-selection-tourney-7}
\end{figure}

\todo[inline]{We have data on the claim below about individuals receiving over 90\% of the selections, but there's nothing in the current draft of this paper. Do we want something concrete, or just leave it like this?} 

From Equation~\ref{tourneyProbEquation}, we see that in our runs using population size 1000 and tournament size 7, the best few individuals will be selected approximately 0.7\% of the time each. This also follows from the fact that every individual will participate in approximately 0.7\% of the tournaments, and the best individual will win each tournament in which it participates.
With tournament selection it would therefore be unlikely to hyper-select many individuals at the 1\% level in a generation, and extremely unlikely for any individuals to be hyper selected at the 5\% or 10\% level.
On the other hand, we have observed numerous examples of lexicase selection rewarding an interesting individual with over 90\% of the selections in a generation. We therefore expect lexicase selection to produce non-zero numbers of hyper-selections at the 5\% and 10\% levels, though without empirical data it is unclear how common these will be.

\section{Experimental setup}
\label{section:experiments}

%\begin{table}[t]
%\centering
%\caption{NOTE: WE CAN PROBABLY REMOVE THIS TABLE AND JUST REFER TO THE FIRST 3 COLUMNS OF TABLE \ref{table:slt-hyper-selection} INSTEAD. The average number of hyper-selected individuals at the 1\%, 5\%, and 10\% levels per generation for both lexicase selection and tournament selection.}
%\label{table:hyper-selections}
%\rowcolors{3}{white}{Gray}
%\begin{tabular}{p{1.8cm} | rrr | rrr}
%\toprule
%  & \multicolumn{3}{c|}{\textbf{Lexicase}} & \multicolumn{3}{c}{\textbf{Tournament}} \\
%\textbf{Problem} & \textbf{1\%}  & \textbf{5\%}  & \textbf{10\%}  & \textbf{1\%}      & \textbf{5\%}      & \textbf{10\%}     \\
%\midrule
%Double Letters             & 12.28 & 0.29 & 0.09 & 0.36 & 0.00 & 0.00 \\
%Replace Space with Newline & 13.39 & 0.38 & 0.11 & 0.28 & 0.00 & 0.00 \\
%String Lengths Backwards   & 6.21  & 0.54 & 0.25 & 0.42 & 0.00 & 0.00 \\
%Vector Average             & 6.99  & 0.02 & 0.01 & 0.91 & 0.00 & 0.00 \\
%Count Odds                 & 0.49  & 0.02 & 0.00 & 0.70 & 0.00 & 0.00 \\
%Mirror Image               & 9.72  & 0.23 & 0.05 & 0.22 & 0.00 & 0.00 \\
%X-Word Lines               & 5.31  & 0.13 & 0.04 & 0.36 & 0.00 & 0.00 \\
%Negative To Zero           & 8.21  & 0.39 & 0.16 & 0.43 & 0.00 & 0.00 \\
%Syllables                  & 5.74  & 0.13 & 0.05 & 0.38 & 0.00 & 0.00 \\
%\bottomrule
%\end{tabular}
%\end{table}

\todo[inline]{I'd be sorely tempted to drop the ``bug'' footnote below, or at least shorten the heck out of it. -- Nic}

\todo[inline]{It's possible that lack of hyperselection is generally higher in successful runs. Can we easily split the numbers according to whether a run was successful or not? -- Nic}

To measure hyper-selection, we gathered data from using lexicase selection and tournament selection with size 7 tournaments on nine benchmark problems from~\cite{Helmuth:2015:GECCO, Helmuth:2015:dissertation}, a subset chosen to exhibit a range of problem requirements and difficulties\footnote{\label{footnote:autoconstructive-rand-integer-bug}Due to a bug, an instruction equivalent to \texttt{exec_noop} was included in the instruction set for the runs on the problems Count Odds, Mirror Image, Vector Average, Double Letters, String Lengths Backwards, and X-Word Lines. We believe that this has a negligible to zero effect on our results. This instruction does nothing when evaluated, simply leaving the stack states unchanged. The instruction \texttt{exec_noop} already appeared in each instruction set once, so this simply added a second equivalent instruction. Additionally, the instruction sets we used always have 50 or more instructions, and usually more than 100 (see~\cite{Helmuth:2015:GECCO} for details). Such large instruction sets dilute the importance of a single instruction, especially one that does nothing.}.
We then calculated the average number of hyper-selected individuals at the 1\%, 5\%, and 10\% levels per generation, which we present in the first three major columns of Table~\ref{table:slt-hyper-selection}. On all problems except one, lexicase selection hyper-selects 5 or more individuals per generation on average at the 1\% level; tournament selection averages less than one per generation on all problems, though always greater than 0.2. Unsurprisingly, tournament selection never hyper-selected an individual at the 5\% or 10\% levels.
On 7 of the 9 problems, lexicase selection hyper-selected one individual at the 5\% level in every 2 to 10 generations on average, and one individual at the 10\% level every 4 to 25 generations on average. 

The Vector Average and Count Odds problems showed much lower levels of hyper-selection with lexicase selection, especially at the 5\% and 10\% levels, indicating that selecting a single individual to parent many of the children in a single generation was rarer on those problems. These two problems were also among the least-solved problems in this subset of the benchmark problems; one hypothesis is that most of the GP runs had trouble getting any traction on these problems, leading to more homogeneous populations and fewer hyper-selection events than on other problems.

\todo[inline]{We could probably check the hypothesis in the last sentence if we wanted to.}

Considering that tournament selection conforms to the probability of selection given in Equation~\ref{tourneyProbEquation} regardless of problem, it is at first surprising that its hyper-selections at the 1\% level vary as much as they do across problems. This difference is likely explained by how often tied individuals appear near the top of the rankings for different problems, since Equation~\ref{tourneyProbEquation} does not strictly hold in the presence of ties. Intuitively, if many individuals tie for the best rank, they will each win fewer tournaments than a single best individual would, since ties in tournaments are broken randomly. Therefore, lower hyper-selection for tournament selection on a problem likely indicates that ties happened more often on those problems, which we have observed anecdotally in a few runs.

\todo[inline]{We could probably get data on the question in the last sentence if we wanted to.\\Tom: We could get some data, but it's not clear to me how we would present it. We'd have to do something like fit a regression line to "number of ties vs. hyper selections". Anyway, it all sounds too complicated to show a point that's nowhere close to our main goals. So, I say leave it as-is.}

The results in Table~\ref{table:slt-hyper-selection} clearly show that lexicase selection gives more of its parent selections to single individuals than tournament selection, both at low levels (1\%) and higher levels (5\% and 10\%) of hyper-selection. This indicates that lexicase selection more often concentrates its selection pressure on single individuals or small groups of individuals than tournament selection, increasing its exploitation of the individuals it selects most often. This data does not indicate whether lexicase selection is hyper-selecting the same individuals that tournament selection ranks highest (those with best total error), or if it actually selects individuals that would receive few or no selections with tournament selection.

In LEXICASE SECTION we referenced results that show GP with lexicase selection significantly outperforms GP with tournament selection across many benchmark problems. We have now observed that lexicase selection often concentrates selection pressure into small numbers of individuals. This raises important questions: can we attribute lexicase selection's success to its ability to concentrate selection in hyper-selection events? Or, is it more important that lexicase selects different individuals than tournament selection, in some sense the ``right'' individuals to drive evolution toward a solution? We will investigate these questions in Section~\ref{section:HyperSelectionandLexicasePerformance}.

%-----------------------------------------------------------
%@@
% - Do I want to say something in this section, or in the other hyper-selection section, about how large hyper-selection events where a single individual "takes over" the population don't really seem to harm lexicase? Momentary blips of loss in diversity, but quickly regains that diversity.
\section{Hyper-Selection and Lexicase Performance}
\label{section:HyperSelectionandLexicasePerformance}

In Section~\ref{section:experiments} we saw that lexicase selection often ends up selecting the same individual many times in one generation, much more often than tournament selection does. This leads to the question of whether the hyper-selections observed in lexicase selection runs are important in driving evolution toward solutions, or if they are simply a side effect of lexicase's algorithm. The alternative is that the individuals that lexicase selection selects the most often are simply different from those that tournament selection selects most often, in particular those with poor total error. In this section we test the hypothesis that the hyper-selections we observed in runs using lexicase are integral to its success, and that without these extreme exploitative events, lexicase selection would perform significantly worse than it does with them.

To test this hypothesis, we designed a new parent selection algorithm that selects the same individuals most often that lexicase does, but has hyper-selection characteristics much closer to tournament selection. The new algorithm, \definition{sampled lexicase-tournament selection} (SLT), starts by sampling the population, which only happens once per generation before selecting any parents. We sample $k$ individuals from the population by running the lexicase selection algorithm and tracking how often each individual is selected. In this work we set $k = 2P$, where $P$ is the population size (set to 1000 in our runs), guaranteeing at least as many samples as the number of parents that will be selected in that generation\footnote{We observe around 1700 parent selections per generation on average, which varies since we randomly select genetic operators, and some operators require one parent where others require two. This means that at most, 2000 parents could be selected in a generation.}. We then use the number of samples each individual received to rank the population from best (most samples) to worst (least samples). Next, every time we need to select a parent, we conduct a tournament, where the winner of the tournament is based on the lexicase-sampled ranking instead of total error. In this experiment we used size 7 tournaments, just like we did with tournament selection in our experiments.

SLT can be seen as a variation of tournament selection in which fitness is based on lexicase sampling instead of total error.
SLT gives the highest probabilities of selection to those individuals that lexicase would select the most often in the population. But, since it uses tournaments for selection, its probability of selecting the individual ranked $i$ in the lexicase-sampled ranking will be same as in tournament selection, as given in Equation~\ref{tourneyProbEquation}. Therefore, we would expect the hyper-selection characteristics of SLT to mirror those of tournament selection, and differ only when the two behave differently with respect to tied individuals in the rankings, especially ties amongst the best individuals.

\todo[inline]{Would it be OK if I alphabetized the list of problems in Tables 1 and 2?}

\begin{table*}[t]
\centering
\caption{
	The average number of hyper-selected individuals at the 1\%, 5\%, and 10\% levels per generation for lexicase selection, tournament selection and SLT selection.
}
\label{table:slt-hyper-selection}
\rowcolors{3}{white}{Gray}
\begin{tabu} to \textwidth {l | rrr | rrr | rrr}
\toprule
  & \multicolumn{3}{c|}{\textbf{Lexicase}} & \multicolumn{3}{c|}{\textbf{Tournament}} & \multicolumn{3}{c}{\textbf{SLT}} \\
\textbf{Problem} & \textbf{1\%}  & \textbf{5\%}  & \textbf{10\%}  & \textbf{1\%}      & \textbf{5\%}      & \textbf{10\%}   & \textbf{1\%}      & \textbf{5\%}      & \textbf{10\%}  \\
\midrule
Double Letters             & 12.28 & 0.29 & 0.09 & 0.36 & 0.00 & 0.00 & 1.54 & 0.00 & 0.00 \\
Replace Space with Newline & 13.39 & 0.38 & 0.11 & 0.28 & 0.00 & 0.00 & 1.56 & 0.00 & 0.00 \\
String Lengths Backwards   & 6.21  & 0.54 & 0.25 & 0.42 & 0.00 & 0.00 & 1.53 & 0.00 & 0.00 \\
Vector Average             & 6.99  & 0.02 & 0.01 & 0.91 & 0.00 & 0.00 & 1.56 & 0.00 & 0.00 \\
Count Odds                 & 0.49  & 0.02 & 0.00 & 0.70 & 0.00 & 0.00 & 1.54 & 0.00 & 0.00 \\
Mirror Image               & 9.72  & 0.23 & 0.05 & 0.22 & 0.00 & 0.00 & 1.55 & 0.00 & 0.00 \\
X-Word Lines               & 5.31  & 0.13 & 0.04 & 0.36 & 0.00 & 0.00 & 1.55 & 0.00 & 0.00 \\
Negative To Zero           & 8.21  & 0.39 & 0.16 & 0.43 & 0.00 & 0.00 & 1.55 & 0.00 & 0.00 \\
Syllables                  & 5.74  & 0.13 & 0.05 & 0.38 & 0.00 & 0.00 & 1.55 & 0.00 & 0.00 \\
\bottomrule
\end{tabu}
\end{table*}

We conducted 100 runs of PushGP using SLT on the same 9 benchmark problems; the hyper-selection results for SLT are also included in Table~\ref{table:slt-hyper-selection}. The first thing to note is that SLT has higher hyper-selection at the 1\% level than tournament selection. Theoretically, we would expect SLT to behave similarly to tournament selection if neither had ties in rank within the population. We believe the differences we see here are a product of ties in total error when using tournament selection, especially near the top of the rankings. The relative consistency of SLT's 1\%-level hyper-selection likely comes from the fact that it rarely had large numbers of tied individuals near the top of the rankings---we expect that tournament selection without ranking ties would also average around 1.55 hyper-selections at the 1\% level per generation.

In these runs, SLT usually had lower hyper-selection at the 1\% level than lexicase selection, and always lower at the 5\% and 10\% levels, on which it never had a non-zero result. Since SLT was designed to have similar hyper-selection characteristics as tournament selection, it is unsurprising that it received no hyper-selections at the upper levels. This means that SLT succeeds in our goal of creating a lexicase-based selection mechanism that never puts as much as 5\% of the parent selections in a generation on a single individual. This contrasts with lexicase selection, which often selects single individuals to make large numbers of the children for the next generation.

Since we have shown that SLT has similar hyper-selection characteristics to tournament selection, let us now examine its performance results in these runs, which we present in Table~\ref{table:slt-results}. Across these 9 problems, SLT shows very similar performance to lexicase selection, and better performance than tournament selection on every problem. Both SLT and lexicase found at least one solution on each of the 9 problems, where tournament selection only found solutions to 6 of the problems. Comparing these methods using a chi-square test with the Holm correction, SLT never has a significantly different success rate compared to lexicase selection. SLT is significantly better than tournament selection on the same problems as lexicase except for Count Odds and X-Word Lines, on which it achieved fewer than the 8 successes necessary to be significantly better than tournament.
 SLT seems to slightly outperform lexicase selection on the easier problems where both find more solutions, and lexicase selection slightly outperforms SLT on the more difficult problems where both find fewer solutions, though the difference is never significant.

\todo[inline]{Tom: Should we add which results are significantly better than tournament? I had those in a different table in my thesis, but it seems like it would be worthwhile to have here.}

\begin{table}[t]
\centering
\caption{Number of successful runs out of 100 for each setting on each problem.}
\label{table:slt-results}
\rowcolors{2}{Gray}{white}
\begin{tabular}{lrrr}
\toprule
\textbf{Problem}                    & \textbf{Lex} & \textbf{Tourn} & \textbf{SLT} \\
\midrule
Double Letters             & 6        & 0          & 4   \\
Replace Space with Newline & 51       & 8          & 61  \\
String Lengths Backwards   & 66       & 7          & 79  \\
Vector Average             & 16       & 14         & 30  \\
Count Odds                 & 8        & 0          & 5   \\
Mirror Image               & 78       & 46         & 84  \\
X-Word Lines               & 8        & 0          & 4   \\
Negative To Zero           & 45       & 10         & 53  \\
Syllables                  & 18       & 1          & 13  \\
\bottomrule
\end{tabular}
\end{table}

\todo[inline]{Should we just drop this next paragraph? -- Nic\\ Tom: I don't think so -- I think it's worth mentioning that the diversity is similar. If it were different, it could be a reason to prefer one or the other even though it didn't affect success rates on these problems, since different diversity might be important on other problems. In fact, if we have room, it might be worthwhile to insert one or two diversity plots here.}
We plotted the diversity across generations from the runs using SLT, as we did for other techniques in Section~\ref{section:exploration}. Interestingly, the diversity plots for SLT were virtually indistinguishable from those of lexicase selection, so we omit them here. Thus, even though the techniques produce significantly different hyper-selection rates, their populations still maintain similar abilities to search widely.
\todo[inline]{Tom: We should tweak the above paragraph. One change should be to cite the lexicase paper and/or my dissertation where we show that lexicase leads to much higher diversity than tourney (and IFS). Or maybe that should be mentioned in the lexicase section?}

These results show that even though SLT has much lower hyper-selection characteristics than lexicase selection, never selecting a single individual to parent more than 5\% of the children in a generation, it nevertheless maintains the problem-solving performance shown by lexicase selection. These results give strong evidence against the hypothesis that lexicase selection's increased exploitation of hyper-selected individuals is important in its ability to outperform tournament selection and IFS. Instead, this suggests that it is more important \textit{which} individuals lexicase selection selects most often, which it has in common with SLT but not tournament selection.

While SLT achieved similar performance to lexicase selection in this experiment, it does not otherwise indicate that it would make a better parent selection mechanism. Notably, it will perform slightly slower than lexicase selection in practice, since it performs both lexicase sampling and then tournaments for selection. Even so, it may merit further examination on other types of problems to see if it behaves differently in other settings.


\section{Conclusions}

The results presented here suggest that while the hyper-selection events caused by lexicase selection do not impact the problem solving performance, they do happen with some frequency. One might speculate that hyper-selection could result in significantly decreased population diversity.

\todo[inline]{Tom: Have we observed differences in diversity? I forget. Say something about them being worth future study. Additionally, it seems that lexicase selection might be good at rediversifying the population after a hyper-selection event.}
\todo[inline]{Tom: Here's a note I had about the above: Look at the hyper-selected individuals, and what happens to the
population diversity in the first few generations afterward an
uber-hyper-selection event. I think in run6 we saw rapid increases in
diversity after a valley, which would be interesting if that's the rule
rather than the outlier. It seems important that lexicase can escape the
un-diverse local optima quickly.}


%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
Omitted for blind review.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{hyperbib}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns

\end{document}
